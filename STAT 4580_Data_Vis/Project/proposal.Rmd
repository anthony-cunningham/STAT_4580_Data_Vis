---
title: "STAT 4580 Project Proposal"
author: "Anthony Cunningham"
date: "March 25, 2019"
output: html_document
---

Kenpom.com (<https://kenpom.com/>) contains data on all NCAA Division 1 Men's Collegiate Basketball teams from 2002-present. This data consists of an offensive, defensive and overall efficiency ratings system, called Adjusted Efficiency Margin, created and updated by the proprietor of this website, Ken Pomeroy. An in-depth explanation of this system can be found here: <https://kenpom.com/blog/ratings-explanation/>. His work is widely cited in popular sports media, and is used as an evaluation tool in deliberating the selection of teams who may participate in the annual NCAA Men's Basketball Tournament every March. Additionally, this data also includes basic Win/Loss data, as well as a measure of luck, defined as the difference in a team's actual vs. expected winning percentage. There is also data on a team's Strength of Schedule, formed using a team's opponents' Adjusted Efficiency Margins.

How are these measures calculated, and what are their interpretations? A team's Adjusted Offensive Efficiency ("AdjO") is the number of points a team is predicted to score per 100 possessions against an average team at a neutral site. According to his explanation (found here: <https://kenpom.com/blog/national-efficiency/>), this is calculated using previous game results, making an adjustment for the pace of a game. Pace is defined as the number of possessions a team has in 40 minutes of game play, the length of a standard collegiate basketball game. A team's Adjusted Defensive Efficiency ("AdjD") is the number of points a team is predicted to allow against an average team at a neutral site per 100 possessions. Adjusted Efficiency Marging ("AdjEM") is the difference between AdjO and AdjD. AdjEM is designed as a predictive tool, aiming to predict the outcome and score of a game. For example, if Team A has an AdjEM of +25, and Team B had an AdjEM of +15, Team A is predicted to win by 10 points if a game is taking place at a neutral site (there is an adjustment for Home-Court Advantage: the home team's AdjEM increases by 2.8, the visiting team's AdjEM decreases by the same amount; I do not know how this was determined). With this data, I plan to answer a variety of questions relating to the historical comparisons of basketball teams and how they stack up with one another.

Note that this data cannot be read directly into R, as the data does not appear as a data file; data is meant to be shown to a viewing audience, and is not meant for analysis. So, I copied and pasted this data into a tab-delimited .txt file, with each year given its own separate file. Each file will then be read into R as a tab-delimited file. Since there are 17 years of data, there are 17 different .txt files that need to be read in, presenting an opportunity to practice automating a repetitive task. This would also be a good opportunity to practice merging datasets together, as we would like to be able reference one dataset when performing visual analyses. In pondering this, I have debated in what form constitutes "tidy" form, where each individual observation takes up its own row. I believe that each Year and Team combination represents an individual observation, as each year's team is unique, even after considering the same team name over time. Players graduate, transfer or turn professional, and it is rare that a team consists of the exact same players in multiple years. Even then, other teams' roster of players change so much so that a teams' results will probably change even with the same players. Additionally, this representation with each Year/Team combination representing one observation makes it easy to clean the data once read into R, as the raw data is already in tidy form within each year. All that needs to be done is to add a "Year" variable to denote the former part of each observations' unique identifier.

Once this data is in its proper form, I will be using these efficiency measures to attempt to answer a variety of questions that may guide my research.

First, it is often debated as to who the greatest team is in each sport, and collegiate basketball is no different. Using this kenpom data, we have a predictive measure with which two teams from two different years would perform at the peak of each teams' respective powers. I will rank teams based on their AdjEM, regardless of year, in hopes of creating a ranking of the best teams from 2002 to 2018. I can represent this as either a Dot Plot or a Bar Chart, perhaps showing the 10 best teams during the given time period. I could also do the same for the Adjusted Offensive and Adjusted Defensive Efficiency measures to stack up the teams with the best offenses and defenses in recent college basketball history. 

An interesting problem arises in comparing teams over time, however, in that Ken Pomeroy has adjusted his methods slightly throughout the years, prior to the 2014 system in particular (https://kenpom.com/blog/pomeroy-ratings-version-2.0/). In this linked article, he claims that he has gone back and "rewritten history" with updated rankings to reflect his current method. However, he must have tinkered with this algorithm again after this article, as examples he gives as to how his changes reflect past rankings are no longer accurate. For example, he claims that the 2008 Davidson team moved from 20th to 7th after the 2014 update. As of this writing, 2008 Davidson is the 11th-ranked team. This is an opportunity to check this data for discretions or obvious shifts in the data due to proprietary updates that are not reflected in past data. Visualization of this data is a powerful tool at my disposal for looking into this potential issue, as we could look at averages and variance over time through the use of a line graph, or a smooth curve with bands to represent variability, or a simple scatter plot with grouping by year, or a pre-post 2014-update grouping.

Another debated topic amongst fans is which conference can be claimed as the best. Conferences are a further organization of teams, and are typically organized by geography. For example, Iowa has been a member of the Big 10 Conference since 1899, along with mostly midwestern and Great Lakes schools. So, debating conference supremacy is akin to debating regional supremacy. I plan to use the average AdjEM of teams within a conference for all years of data to come up with a definitive ranking of conference dominance.

Another potential topic of interest is to investigate competitive balance, both within a conference and throughout the sport. Do one or two teams win the conference, or the national championship, every year, or are titles evenly-dispersed, where someone new is more liable to pop-up and challenge for a championship? Intuitively, I feel that, on a national level, college basketball is dominated by a few elite teams every year, while most of the now 353 teams are left with almost no chance at a championship. However, the annual single-elimination tournament does a good job in mitigating this somewhat, as a single game is highly-variant, leaving greater chance to a less-talented team beating a powerhouse in a single-game scenario. The point is that who wins the national championship each year may not have been the best team, but the team that has played the best over the course of three weeks in late-March and early-April. So, looking at who wins titles may not be the most accurate assessment of competitive balance. Instead, we can use Win/Loss data over the course of a full season to measure the variance in win totals; this can be performed within each year or over all years. We can compare competitve balance measure by year to visually analyze the trend of competitive balance in men's collegiate basketball. We can also perform the same analyses within each conference.

Perhaps there is more meat on the bone as to potential research questions, but I hope that this is at least a quality start in focusing my research for this project.